

Wearable devices increasingly use **photoplethysmography (PPG)** along with motion sensors (accelerometers and gyroscopes) to track sleep. By hierarchically transforming raw signals through preprocessing, feature extraction, and temporal analysis, these devices can classify sleep stages (e.g. wake, light, deep, REM). Below, we present a comprehensive transformation table, flowcharts, code structure, and deep technical insights for such a pipeline. This approach builds on best practices from research and industry, as multi-sensor wearables (PPG + motion) have been shown to outperform motion-only trackers for multi-stage sleep classification ( [Evaluating reliability in wearable devices for sleep staging - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC10948771/#:~:text=from%20the%20past%20decade%2C%20evaluating,performance%20analysis%20of%20commercial%20algorithms) ).

## Hierarchical Transformation Stages and Techniques

The following table outlines each processing stage – from **Raw Data Acquisition** to **Aggregation & Classification** – including the transformations/algorithms applied, typical parameters, best practice tips, and references:

|**Stage**|**Technique / Transformation**|**Description** (Purpose)|**Parameters (Typical Ranges)**|**Best Practices** (Tips)|**References**|
|---|---|---|---|---|---|
|**Raw Acquisition**|**PPG Signal Capture** (Wrist PPG)|Photoplethysmography sensor measures blood volume changes via optical LED (e.g. green) and photodiode. Raw output is an analog waveform converted to digital samples. Typical sampling rates 25–100 Hz on wearables ([[PDF] Wearable Photoplethysmography Devices - Peter Charlton](https://peterhcharlton.github.io/publication/wearable_ppg_chapter/Wear_PPG_Chapter_20210323.pdf#:~:text=Charlton%20peterhcharlton,be%20estimated%20from%20PPG)) ([[PDF] Optical Heart Rate Monitoring (OHRM) on Wearables](https://www.ti.com/lit/SBAA564#:~:text=The%20clinical%20range%20of%20the,referred%20to%20as%20the%20pulse)).|– Sampling rate: 25–100 Hz (≥25 Hz suffices for HR ([[PDF] Wearable Photoplethysmography Devices - Peter Charlton](https://peterhcharlton.github.io/publication/wearable_ppg_chapter/Wear_PPG_Chapter_20210323.pdf#:~:text=Charlton%20peterhcharlton,be%20estimated%20from%20PPG)))– Wavelength: green (~525 nm) commonly used– Resolution: 12–16 bit ADC|Ensure good sensor contact (snug wrist fit) to reduce motion artifacts. Minimize ambient light leakage into sensor. Balance LED intensity to get a strong signal without saturating or draining battery ([](https://peterhcharlton.github.io/publication/wearable_ppg_chapter/Wear_PPG_Chapter_20210323.pdf#:~:text=2,can%20be%20achieved%20by%20using)). During high motion, consider intermittent sampling or pausing PPG to save power since signal quality drops ([](https://peterhcharlton.github.io/publication/wearable_ppg_chapter/Wear_PPG_Chapter_20210323.pdf#:~:text=2,can%20be%20achieved%20by%20using)).|([|

```
        Evaluating reliability in wearable devices for sleep staging - PMC
    ](https://pmc.ncbi.nlm.nih.gov/articles/PMC10948771/#:~:text=from%20the%20past%20decade%2C%20evaluating,performance%20analysis%20of%20commercial%20algorithms)) ([[PDF] Optical Heart Rate Monitoring (OHRM) on Wearables](https://www.ti.com/lit/SBAA564#:~:text=The%20clinical%20range%20of%20the,referred%20to%20as%20the%20pulse))                 |
```

| **Raw Acquisition** | **Accelerometer (ACC)** (3-axis) | Tri-axial accelerometer records acceleration forces (x, y, z) to capture movement and orientation ([How does a smartwatch monitor sleep? - Tech With Muchiri](https://techwithmuchiri.com/how-does-a-smartwatch-monitor-sleep/#:~:text=Muchiri%20techwithmuchiri,periods%20of%20activity%20and%20rest)). Often sampled at 25–50 Hz in sleep trackers. Measures both dynamic motion and static gravity. | – Sampling rate: ~50 Hz (range 25–100 Hz)– Dynamic range: ±2–8 g (device-dependent)– Sensitivity: ~1–16 mg/LSB | Wear device consistently on the same wrist to maintain orientation reference. Calibrate or initialize orientation (gravity vector) if needed for posture detection. Ensure no loose straps (prevents false high g spikes). Use power-saving modes (e.g., lower sampling when stationary) to extend battery. | ([How does a smartwatch monitor sleep? - Tech With Muchiri](https://techwithmuchiri.com/how-does-a-smartwatch-monitor-sleep/#:~:text=Muchiri%20techwithmuchiri,periods%20of%20activity%20and%20rest)) ([Sampling frequency affects the processing of Actigraph raw ...](https://journals.physiology.org/doi/10.1152/japplphysiol.00628.2015#:~:text=The%20standard%20proprietary%20algorithm%20filters,4%20software%20version)) | | **Raw Acquisition** | **Gyroscope (GYR)** (3-axis) | Tri-axial gyroscope measures angular velocity (rotational movement) of the device. Complementary to ACC for detecting subtle motions like wrist rotations or posture changes. Sampling rate often matches accelerometer (e.g. 25–50 Hz). | – Sampling rate: ~50 Hz– Range: ±250–500 °/s (device-dependent)– Resolution: ~0.01–0.1 °/s/LSB | Combine gyro with accelerometer for more robust motion detection (fusion can distinguish true movement from noise). Calibrate zero-offset (bias) periodically to avoid drift in angle integration. Use gyro data especially for detecting rotations (e.g. roll-over events) that accelerometer might not capture distinctly. | ([How does a smartwatch monitor sleep? - Tech With Muchiri](https://techwithmuchiri.com/how-does-a-smartwatch-monitor-sleep/#:~:text=Muchiri%20techwithmuchiri,periods%20of%20activity%20and%20rest)) (orientation) | | **Preprocessing** | **Bandpass Filtering (PPG)** | Remove baseline wander (DC) and high-frequency noise from PPG, retaining heart-beat oscillations. Typically implemented with a digital band-pass filter targeting the heart rate frequency band. This improves signal quality for downstream peak detection ( [Robust PPG Peak Detection Using Dilated Convolutional Neural Networks - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC9414657/#:~:text=are%20commonly%20used%20for%20peak,12) ). | – Cutoff frequencies: ~0.4–4 Hz (covers ~24–240 bpm) ([[PDF] Optical Heart Rate Monitoring (OHRM) on Wearables](https://www.ti.com/lit/SBAA564#:~:text=The%20clinical%20range%20of%20the,referred%20to%20as%20the%20pulse))– Filter type: Butterworth or FIR (order 2–5)– Zero-phase (e.g. forward-backward) filtering to avoid phase shift | Use **narrow band** around plausible heart rates to eliminate respiratory drift and noise ([](https://peterhcharlton.github.io/publication/wearable_ppg_chapter/Wear_PPG_Chapter_20210323.pdf#:~:text=is%20beneficial%20to%20strongly%20filter,signals%20outside%20of%20this%20narrow)). For sleep, HR typically 40–100 bpm (0.7–1.7 Hz), so adjust band accordingly. Ensure filter has flat passband in heart rate range and adequate attenuation of 50/60 Hz interference. Apply filtfilt (zero-phase) so that R-peak timing in PPG is preserved. | ([](https://peterhcharlton.github.io/publication/wearable_ppg_chapter/Wear_PPG_Chapter_20210323.pdf#:~:text=is%20beneficial%20to%20strongly%20filter,signals%20outside%20of%20this%20narrow)) ([Correlation analysis of heart rate variability between PPG and ECG ...](https://www.researchgate.net/publication/321411707_Correlation_analysis_of_heart_rate_variability_between_PPG_and_ECG_for_wearable_devices_in_different_postures#:~:text=,level%2C%20signal%20smoothing%2C%20and)) | | **Preprocessing** | **Motion Artifact Correction (PPG)** | Reduce motion-induced artifacts in PPG using signal processing or sensor fusion. Approaches include adaptive filtering (e.g. LMS) using ACC as reference noise, wavelet-based denoising, and removing segments with excessive motion. Goal is to isolate true cardiovascular pulses from motion noise. | – Adaptive filter step-size (μ) ~0.001–0.01 (for LMS)– Wavelet: choose mother wavelet (e.g. Daubechies) and decomposition level (3–6)– Artifact threshold: e.g. ACC > 0.5 g indicates motion artifact | **Adaptive filtering**: use accelerometer signals to subtract correlated motion noise from PPG ([detect and remove motion artifacts from ppg signal using lms ...](https://www.mathworks.com/matlabcentral/answers/828575-detect-and-remove-motion-artifacts-from-ppg-signal-using-lms-adaptive-filter#:~:text=detect%20and%20remove%20motion%20artifacts,be%20configured%20to%20minimize)). **Wavelet MRA**: decompose PPG, identify and remove artifact components ([Frontiers | Motion Artifact Removal Techniques for Wearable EEG and PPG Sensor Systems](https://www.frontiersin.org/journals/electronics/articles/10.3389/felec.2021.685513/full#:~:text=wavelet%20transform%20%28I,respiratory%20data%20can%20be%20restored)) (e.g. dual-tree wavelet to separate motion vs cardiac vs respiratory components). If motion is too large (ACC beyond threshold), mark that epoch’s PPG data as low-quality ([](https://peterhcharlton.github.io/publication/wearable_ppg_chapter/Wear_PPG_Chapter_20210323.pdf#:~:text=2,can%20be%20achieved%20by%20using)) and rely more on accelerometer for that period. | ([Frontiers | Motion Artifact Removal Techniques for Wearable EEG and PPG Sensor Systems](https://www.frontiersin.org/journals/electronics/articles/10.3389/felec.2021.685513/full#:~:text=wavelet%20transform%20%28I,respiratory%20data%20can%20be%20restored)) ([](https://peterhcharlton.github.io/publication/wearable_ppg_chapter/Wear_PPG_Chapter_20210323.pdf#:~:text=2,can%20be%20achieved%20by%20using)) | | **Preprocessing** | **Acceleration Filtering (ACC)** | Separate meaningful motion from gravity and noise. Often a band-pass or high-pass filter is applied to accelerometer data to remove the static gravity component and very slow drift, while also filtering out high-frequency sensor noise. The result highlights body movements relevant to sleep detection (e.g. tosses and turns). | – High-pass cutoff: ~0.2–0.5 Hz (to remove DC/gravity)– Low-pass cutoff: ~2.5–3 Hz (to remove high-frequency jitter) ([Sampling frequency affects the processing of Actigraph raw ...](https://journals.physiology.org/doi/10.1152/japplphysiol.00628.2015#:~:text=The%20standard%20proprietary%20algorithm%20filters,4%20software%20version))– Filter: 4th-order Butterworth or moving average for simplicity | Subtract a low-pass filtered version (≈0.2 Hz) of ACC from raw to get **dynamic acceleration** (motion). This isolates movement from posture. Use magnitude of 3-axis vector (√(x²+y²+z²)) to condense motion into one signal for threshold-based methods. Ensure filter does not distort the timing of brief movements – a short FIR filter can act as an activity integrator as used in actigraphy ( [On the Unification of Common Actigraphic Data Scoring Algorithms - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC8472753/#:~:text=applications%20of%20actigraphy,Proposed%20framework%20provides%20a%20robust) ). | ([Sampling frequency affects the processing of Actigraph raw ...](https://journals.physiology.org/doi/10.1152/japplphysiol.00628.2015#:~:text=The%20standard%20proprietary%20algorithm%20filters,4%20software%20version)) ( [On the Unification of Common Actigraphic Data Scoring Algorithms - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC8472753/#:~:text=applications%20of%20actigraphy,Proposed%20framework%20provides%20a%20robust) ) | | **Preprocessing** | **Gyro Smoothing & Integration** | Clean gyroscope signal by removing noise (e.g. via low-pass filtering ~5 Hz, since most relevant motions are low-frequency). Optionally, integrate angular velocity to estimate orientation changes over time or detect significant rotation events. | – Low-pass cutoff: ~5 Hz (to reduce noise)– Integration interval: match epoch (e.g. 30 s) for net angle change– Threshold for event: e.g. >30° change counted as movement | Use complementary filter or sensor fusion (e.g. Kalman filter combining ACC & gyro) for more stable orientation estimation. Zero-out gyro data below a noise threshold to avoid integrating noise. Focus on **significant rotations** – e.g., a sharp change in orientation may indicate a turnover or arm movement (potentially marking an awake moment). Gyro features can be omitted if redundant with ACC, but can improve detection of rotational motions (like arm twisting) that ACC might miss. | _N/A (gyro usage is less common in literature, heuristic best practices)_ | | **Feature Extraction** | **Peak Detection (PPG)** | Identify peaks (e.g. systolic peaks) in the filtered PPG waveform to compute heart beats. Common algorithms use adaptive thresholding or zero-crossing of first derivative ( [Robust PPG Peak Detection Using Dilated Convolutional Neural Networks - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC9414657/#:~:text=are%20commonly%20used%20for%20peak,12) ). Peak timestamps are used to derive inter-beat intervals (IBIs) and instantaneous heart rate (HR). | – Min. peak distance: ~0.3–1.5 s (corresponding to 40–200 bpm max range)– Threshold update: e.g. 0.5× average peak amplitude (adaptive)– Search window: ~150 ms around expected peak (for refining timing) | Use an **adaptive threshold** that adjusts with signal amplitude and noise ( [Robust PPG Peak Detection Using Dilated Convolutional Neural Networks - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC9414657/#:~:text=are%20commonly%20used%20for%20peak,12) ) (e.g. scale recent average peak height). Incorporate refractory period: ignore peaks too close to the last (to avoid double-counting high-frequency noise). Optionally, enhance PPG signal by squaring or derivative to emphasize peaks (similar to ECG’s Pan-Tompkins algorithm). Validate detected peaks by checking physiologic plausibility (IBI not drastically shorter/longer than neighbors). | ( [Robust PPG Peak Detection Using Dilated Convolutional Neural Networks - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC9414657/#:~:text=On%20the%20other%20hand%2C%20various,In%20some%20cases%2C%20the) ) ( [Robust PPG Peak Detection Using Dilated Convolutional Neural Networks - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC9414657/#:~:text=In%20addition%2C%20transform,14%20%2C%2038) ) | | **Feature Extraction** | **Heart Rate & HRV Metrics (PPG)** | Compute heart rate (beats per minute) from detected IBIs, and extract **heart rate variability (HRV)** features that reflect autonomic nervous system activity. HRV metrics (time, frequency, nonlinear) are calculated per epoch to help distinguish sleep stages (e.g. higher HRV in deep sleep vs lower in REM). | – HR calculation: 60/IBI (for each beat or mean per epoch)– Time-domain HRV: SDNN, RMSSD, pNN50, etc.– Freq-domain HRV: LF (0.04–0.15 Hz) & HF (0.15–0.4 Hz) power, LF/HF ratio (requires ~1–5 min window)– Nonlinear: SD1/SD2 (Poincaré), SampEn | Prefer **time-domain HRV** for short epochs (30–60 s) since frequency-domain features need longer windows (5 min for stable LF/HF). Compute HRV on clean IBIs – filter out artifact IBIs or interpolate missing beats. Features like RMSSD (reflecting vagal tone) can indicate deep sleep when higher ([Heart Rate Variability and Sleep - Amerisleep](https://amerisleep.com/blog/heart-rate-variability-and-sleep/#:~:text=Heart%20Rate%20Variability%20and%20Sleep,you%20cycle%20through%20the)). Use multiple HRV features: in one study, 132 HRV features (time, freq, non-linear) were extracted per 30 s epoch ( [It is All in the Wrist: Wearable Sleep Staging in a Clinical Population versus Reference Polysomnography - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC8253894/#:~:text=built%20and%20used%20as%20input,axial%20accelerometer) ). Normalize or log-transform skewed features (e.g. HF power) for ML algorithms. | ( [It is All in the Wrist: Wearable Sleep Staging in a Clinical Population versus Reference Polysomnography - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC8253894/#:~:text=built%20and%20used%20as%20input,axial%20accelerometer) ) ( [Sleep stage classification from heart-rate variability using long short-term memory neural networks - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC6775145/#:~:text=Automated%20sleep%20stage%20classification%20using,R%26K) ) | | **Feature Extraction** | **Respiratory Features (PPG & ACC)** _(optional)_ | Derive respiration rate or patterns from signals. PPG can reveal respiratory modulation (via amplitude or baseline oscillations), and accelerometer/gyro can detect chest movements. Respiratory rate varies with sleep stage (e.g. slower, regular breathing in deep sleep). | – Respiratory band: ~0.1–0.3 Hz (6–18 breaths/min)– Method: band-pass filter PPG baseline or use wavelet to isolate breathing component ([Frontiers | Motion Artifact Removal Techniques for Wearable EEG and PPG Sensor Systems](https://www.frontiersin.org/journals/electronics/articles/10.3389/felec.2021.685513/full#:~:text=wavelet%20transform%20%28I,respiratory%20data%20can%20be%20restored)); or use accelerometer on chest (if device location permits)– Feature: avg breaths/min, respiratory variability | If using PPG, apply a **wavelet or filtering** to separate respiratory-induced variations without disturbing cardiac peaks ([Frontiers | Motion Artifact Removal Techniques for Wearable EEG and PPG Sensor Systems](https://www.frontiersin.org/journals/electronics/articles/10.3389/felec.2021.685513/full#:~:text=wavelet%20transform%20%28I,respiratory%20data%20can%20be%20restored)). Use peak-to-trough intervals of the PPG baseline to estimate breathing. For wrist devices, respiratory signals are subtle; if available, use a chest/torso accelerometer for clearer respiratory movement. Breathing rate can help identify REM (more irregular breathing) vs deep (more stable, slow breathing). Ensure the method is validated as PPG-derived respiration can be noisy. | ([Frontiers | Motion Artifact Removal Techniques for Wearable EEG and PPG Sensor Systems](https://www.frontiersin.org/journals/electronics/articles/10.3389/felec.2021.685513/full#:~:text=wavelet%20transform%20%28I,respiratory%20data%20can%20be%20restored)) | | **Feature Extraction** | **Activity Counts (ACC)** | Compute quantitative measures of movement per epoch from accelerometer data – e.g., **activity count** (a proxy for how much movement occurred). Many algorithms integrate or sum the accelerations over each epoch or count threshold crossings. These features correlate with sleep/wake (high activity = likely wake). | – Epoch length for counting: 30 or 60 s– Count method: e.g. sum of |Δacc| every second, or count of peaks above 0.1 g– Threshold: define noise floor (e.g. 0.02 g) to ignore minor vibrations | Use a method consistent with actigraphy standards: e.g., band-pass filter ACC (0.25–2.5 Hz) and sum the absolute differences ([Sampling frequency affects the processing of Actigraph raw ...](https://journals.physiology.org/doi/10.1152/japplphysiol.00628.2015#:~:text=The%20standard%20proprietary%20algorithm%20filters,4%20software%20version)) or use a proprietary count algorithm ( [On the Unification of Common Actigraphic Data Scoring Algorithms - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC8472753/#:~:text=applications%20of%20actigraphy,Proposed%20framework%20provides%20a%20robust) ). Calibrate threshold for movement detection to minimize classifying small twitches as wake (avoid false awakenings). Also compute **max acceleration** or number of large movements to detect vigorous motion vs restlessness. These features help separate quiet sleep from periods of wake or REM (which can have bursts of movement). | ([Sampling frequency affects the processing of Actigraph raw ...](https://journals.physiology.org/doi/10.1152/japplphysiol.00628.2015#:~:text=The%20standard%20proprietary%20algorithm%20filters,4%20software%20version)) ( [On the Unification of Common Actigraphic Data Scoring Algorithms - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC8472753/#:~:text=applications%20of%20actigraphy,Proposed%20framework%20provides%20a%20robust) ) | | **Feature Extraction** | **Postural Changes (ACC/GYR)** | Determine changes in body or limb posture. Using accelerometer orientation (gravity vector) or integrating gyro, detect if the user’s position changed significantly during an epoch. A large change may indicate turnover (common during light sleep or arousals). | – Orientation from ACC: compute tilt angles (pitch/roll) from low-pass ACC– Compute change in orientation between start vs end of epoch (or across epochs)– Threshold: e.g. >20° change = posture shift | Low-pass filter ACC at ~0.1–0.2 Hz to get gravity vector (device tilt). Compare orientation between epochs – if it changes beyond a threshold, flag a posture change event. This can serve as a feature indicating arousal or lighter sleep. Combine with gyro data for precision in detecting quick rotations. Avoid misclassifying gradual drifts as changes (set a reasonable threshold). Postural changes can be infrequent; consider time of night (more common in transitions and REM). | _Empirical best practice_ | | **Feature Extraction** | **Combined Feature Vector** | Assemble all extracted features for each epoch into a feature vector. This may include statistical summaries (mean, variance of signals), domain-specific metrics (HRV, activity counts), and contextual flags (e.g. low signal quality flag). The vector represents the state of that epoch for classification. | – Feature dimensions: e.g. 10–150 features per epoch (depending on complexity)– Examples: mean HR, std HR, RMSSD, LF/HF, movement count, posture change (0/1), time of night (minutes since sleep start) | Normalize features (e.g. z-score per user or min-max across night) to avoid dominance by large-scale variables like raw counts. Optionally apply **feature selection** or PCA if using classical ML to reduce redundancy. Incorporate features capturing context: e.g., a “time into sleep” feature can proxy circadian effects (predictable REM timing) ( [Sleep stage prediction with raw acceleration and photoplethysmography heart rate data derived from a consumer wearable device - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC6930135/#:~:text=contributions%20of%20multiple%20features%20,ethnic%20Study%20of%20Atherosclerosis) ). Handle missing features (e.g., if no valid HRV due to noise, set to population mean or use an indicator for missing). | ( [It is All in the Wrist: Wearable Sleep Staging in a Clinical Population versus Reference Polysomnography - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC8253894/#:~:text=built%20and%20used%20as%20input,axial%20accelerometer) ) ( [Sleep stage prediction with raw acceleration and photoplethysmography heart rate data derived from a consumer wearable device - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC6930135/#:~:text=contributions%20of%20multiple%20features%20,ethnic%20Study%20of%20Atherosclerosis) ) | | **Temporal Analysis** | **Epoch Segmentation** | Divide the continuous signal stream into discrete time epochs (windows), typically 30 seconds each, aligned to standard sleep staging criteria ( [An automated heart rate-based algorithm for sleep stage classification: Validation using conventional polysomnography and an innovative wearable electrocardiogram device - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC9584568/#:~:text=This%20validation%20study%20highlights%20the,simultaneous%20PSG%20collection%20using%20SOMNOtouch) ). All features are computed per epoch. Longer windows (e.g. 60 s) may be used for simpler two-stage (sleep/wake) analysis in actigraphy. | – Epoch length: 30 s (standard for sleep stages) ( [An automated heart rate-based algorithm for sleep stage classification: Validation using conventional polysomnography and an innovative wearable electrocardiogram device - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC9584568/#:~:text=This%20validation%20study%20highlights%20the,simultaneous%20PSG%20collection%20using%20SOMNOtouch) )– Overlap: 0% (distinct epochs) or slight overlap if using sliding window for continuity– Annotation: each epoch gets one sleep stage label in training data | Follow clinical convention: 30 s epochs for staging ( [An automated heart rate-based algorithm for sleep stage classification: Validation using conventional polysomnography and an innovative wearable electrocardiogram device - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC9584568/#:~:text=This%20validation%20study%20highlights%20the,simultaneous%20PSG%20collection%20using%20SOMNOtouch) ) to enable comparison with PSG. Ensure epoch boundaries are synchronized across PPG and ACC signals (after resampling if needed) so features align in time. If raw data isn’t an exact multiple of epoch length, handle partial epochs (pad or discard). For specialized use (e.g. wake detection), 60 s epochs can smooth variability but may reduce sensitivity to short events. | ( [An automated heart rate-based algorithm for sleep stage classification: Validation using conventional polysomnography and an innovative wearable electrocardiogram device - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC9584568/#:~:text=This%20validation%20study%20highlights%20the,simultaneous%20PSG%20collection%20using%20SOMNOtouch) ) | | **Temporal Analysis** | **Contextual Smoothing** | Incorporate temporal context to smooth or refine stage predictions. Adjacent epochs are often correlated (sleep stages typically last several minutes), so analyzing sequences can improve stability. Techniques include moving averages on features, hidden Markov models (HMM) on outputs, or recurrent neural networks across epoch sequences. | – Context window: e.g. ±2 epochs (1 min) for feature smoothing– HMM state transition probabilities (e.g. enforce realistic stage transitions)– RNN memory: e.g. LSTM with sequence length of dozens of epochs | Apply a **median filter or majority vote** over a few neighboring epoch predictions to eliminate implausible isolated stage jumps. In ML models, feed a **sequence of epoch features** into a recurrent model (LSTM/GRU) to learn transitions ( [It is All in the Wrist: Wearable Sleep Staging in a Clinical Population versus Reference Polysomnography - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC8253894/#:~:text=The%20combined%20HRV%20and%20body,outputs%20the%20posterior%20probability%20for) ). Use HMM post-processing to enforce rules (e.g. cannot jump from deep to REM without passing through lighter stage). Tuning the transition penalties in an HMM can significantly improve stage continuity. Always evaluate that smoothing doesn’t obscure real short events (like brief awakenings). | ( [It is All in the Wrist: Wearable Sleep Staging in a Clinical Population versus Reference Polysomnography - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC8253894/#:~:text=The%20combined%20HRV%20and%20body,outputs%20the%20posterior%20probability%20for) ) ( [Sleep stage classification from heart-rate variability using long short-term memory neural networks - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC6775145/#:~:text=methods%20however%20are%20limited%20in,00) ) | | **Aggregation & Classification** | **Feature Aggregation over Night** | (Optional) Aggregate metrics over the entire night or large intervals for summary. E.g., compute total activity count in each sleep period, or average HRV in first sleep cycle. This is more for reporting sleep quality metrics than for epoch-level classification. | – Interval: whole night or sleep segments (e.g. per sleep cycle)– Metrics: sleep efficiency, total sleep time, average HR, etc. | Ensure definitions follow standard sleep stats (e.g. sleep efficiency = time asleep / time in bed). These aggregated metrics can be used to inform personalized thresholds (e.g. a person’s typical nighttime HR range). While not directly used in classifying each epoch, they provide context and can be input to secondary analyses (like detecting overall sleep quality or anomalies). | ( [Evaluating reliability in wearable devices for sleep staging - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC10948771/#:~:text=accelerometer%20and%20photoplethysmography%20,performance%20analysis%20of%20commercial%20algorithms) ) (value of combined sensors for overall staging) | | **Aggregation & Classification** | **Machine Learning Classifier** (Classical) | Use a trained model to classify each epoch’s sleep stage based on its feature vector. Classical approaches include decision trees, Random Forests, support vector machines (SVM), or logistic regression. These models output a stage label (e.g. Wake, Light, Deep, REM) for the epoch. | – Algorithm examples: Random Forest (100–500 trees), SVM (RBF kernel, C tuned via CV), etc.– Input: feature vector per epoch– Output: discrete stage (2-class up to 4-class) | Train on large labeled dataset (PSG ground truth) covering diverse subjects for generalization ( [Evaluating reliability in wearable devices for sleep staging - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC10948771/#:~:text=from%20the%20past%20decade%2C%20evaluating,performance%20analysis%20of%20commercial%20algorithms) ). Balance classes in training or use class weights (REM and Wake often underrepresented). Feature scaling is critical for SVM/linear models. Random forests handle unscaled features and can rank feature importance. Simpler models (e.g. logistic) can be interpretable but might sacrifice accuracy; more complex ensemble or nonlinear models often perform better but need careful tuning. Cross-validate to prevent overfitting, and report standard metrics (overall accuracy, per-stage recall, Cohen’s kappa) for evaluation. | ( [Sleep stage prediction with raw acceleration and photoplethysmography heart rate data derived from a consumer wearable device - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC6930135/#:~:text=contributions%20of%20multiple%20features%20,ethnic%20Study%20of%20Atherosclerosis) ) ( [Sleep stage prediction with raw acceleration and photoplethysmography heart rate data derived from a consumer wearable device - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC6930135/#:~:text=contributions%20of%20multiple%20features%20,wake%20classification%2C%20our%20method) ) | | **Aggregation & Classification** | **Deep Learning Classifier** (Sequential) | Design a neural network that learns sleep staging directly from features or even raw signals. Examples: convolutional neural network (CNN) to automatically extract features, or recurrent neural network (RNN/LSTM) to leverage temporal patterns ( [It is All in the Wrist: Wearable Sleep Staging in a Clinical Population versus Reference Polysomnography - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC8253894/#:~:text=The%20combined%20HRV%20and%20body,outputs%20the%20posterior%20probability%20for) ). These networks can classify multi-class sleep stages and potentially capture complex patterns (e.g. cardiac variability trends across sleep cycles ( [Sleep stage classification from heart-rate variability using long short-term memory neural networks - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC6775145/#:~:text=methods%20however%20are%20limited%20in,00) )). | – Architecture: e.g. 1D-CNN with filters on time-series input; or multi-layer LSTM on sequence of epochs ( [It is All in the Wrist: Wearable Sleep Staging in a Clinical Population versus Reference Polysomnography - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC8253894/#:~:text=The%20combined%20HRV%20and%20body,outputs%20the%20posterior%20probability%20for) )– Training: epoch size ~30 s segments, batch training with labeled data– Output: softmax probabilities for each class (Wake/Light/Deep/REM) | Large datasets are essential to train deep models to avoid overfitting. Use regularization (dropout, L2) and validate on separate cohorts ( [An automated heart rate-based algorithm for sleep stage classification: Validation using conventional polysomnography and an innovative wearable electrocardiogram device - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC9584568/#:~:text=Materials%20and%20methods) ). Leverage transfer learning or pre-training (e.g. unsupervised learning on large wearable dataset) if labeled data is limited. **Interpretability** is a challenge – consider examining learned features or using explainable AI techniques ( [An automated heart rate-based algorithm for sleep stage classification: Validation using conventional polysomnography and an innovative wearable electrocardiogram device - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC9584568/#:~:text=directly%20fed%20into%20the%20model%2C,machine%20learning%20have%20enables%20visualization) ). When designed well, deep models (e.g. an LSTM capturing long-term HRV patterns) have achieved ~75–80% accuracy for 4-stage classification, matching state-of-art for HRV-based staging ( [Sleep stage classification from heart-rate variability using long short-term memory neural networks - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC6775145/#:~:text=541,based%20sleep%20stage%20classification.%20Further) ) ( [It is All in the Wrist: Wearable Sleep Staging in a Clinical Population versus Reference Polysomnography - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC8253894/#:~:text=The%20combined%20HRV%20and%20body,outputs%20the%20posterior%20probability%20for) ). | | **Aggregation & Classification** | **Decision Rules / Thresholds** (Heuristic) | A simpler alternative (often for binary sleep/wake): apply rules based on feature thresholds. E.g., if activity count = 0 and heart rate is low for >5 min, classify Deep sleep; if high movement, classify Wake. These rule-based methods are fast and transparent but usually limited to distinguishing sleep vs wake. | – Example rule: Wake if ACC count > threshold OR HR > X bpm; else Sleep.– Multi-stage rules: e.g. Deep if HRV high & low movement; REM if low movement & HRV low/moderate & time of night late. | Calibrate thresholds per individual if possible (personalized baseline heart rate, etc.). Use known physiological patterns: e.g., REM often has near-zero motion but heart rate closer to wake levels – a rule can exploit that. Many commercial devices began with proprietary rule-based algorithms. Ensure to update rules when conditions conflict (e.g. movement indicating wake might override HR suggesting deep sleep during exercise). While not as accurate as ML, rules can achieve reasonable sleep/wake accuracy (often ~85%+) and can serve as a fallback or to initialize ML models. | ( [On the Unification of Common Actigraphic Data Scoring Algorithms - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC8472753/#:~:text=applications%20of%20actigraphy,Proposed%20framework%20provides%20a%20robust) ) ( [Evaluating reliability in wearable devices for sleep staging - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC10948771/#:~:text=accelerometer%20and%20photoplethysmography%20,performance%20analysis%20of%20commercial%20algorithms) ) | | **Post-Classification** | **Stage Refinement & Output** | Final stage where the sequence of preliminary epoch-by-epoch stages is optionally smoothed or adjusted, and then output to the user. This could involve combining similar stages (e.g. Light and REM as “Light sleep” in simpler reports), and computing sleep statistics from the hypnogram (the sequence of stages over the night). | – Smoothing filter: e.g. 3-epoch median filter on predicted stages– Output hypnogram: hypnogram resolution 30 s/epoch– Sleep stats: total time in each stage, sleep latency, etc. | Clearly communicate performance (e.g. mark low-confidence regions). Apply **logical fixes** if needed (e.g., if first epoch was classified as REM, but it’s improbable to jump straight into REM, one might override it to Light sleep). Such adjustments should be minimal and ideally evidence-based. Finally, aggregate results into user-friendly metrics (sleep efficiency, etc.) that are consistent with the classified stages. Validate the entire pipeline against gold-standard PSG to ensure that these transformations collectively achieve high agreement (e.g. kappa > 0.6 for 4-stage classification) ( [It is All in the Wrist: Wearable Sleep Staging in a Clinical Population versus Reference Polysomnography - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC8253894/#:~:text=Results) ) ( [Sleep stage classification from heart-rate variability using long short-term memory neural networks - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC6775145/#:~:text=541,based%20sleep%20stage%20classification.%20Further) ). | ( [It is All in the Wrist: Wearable Sleep Staging in a Clinical Population versus Reference Polysomnography - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC8253894/#:~:text=Results) ) ( [Sleep stage prediction with raw acceleration and photoplethysmography heart rate data derived from a consumer wearable device - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC6930135/#:~:text=scored%2090,disclosed%20mathematical%20methods%20to%20improve) ) |

**Table:** Hierarchical signal transformations from raw sensor data to sleep stage classification. Each stage involves specific algorithms and parameters. Best practices and references are provided for reliability and performance.

## Signal Processing Flowcharts

The flowcharts below illustrate the end-to-end pipeline for processing wearable signals (PPG, accelerometer, gyroscope) into sleep stage predictions. The first diagram shows the **sensor-specific processing** streams and their convergence, while the second focuses on the **hierarchical pipeline** from raw data through feature extraction to classification.

```mermaid
flowchart TD
    %% Sensor-specific processing subgraphs
    subgraph PPG Signal Processing
        PPGraw([Raw PPG Signal<br/>(Optical waveform)]) --> PPGfilt[Bandpass Filter<br/>(0.5-4 Hz)]
        PPGfilt --> PPGclean[Motion Artifact Removal]
        PPGclean --> PPGpeaks[Peak Detection<br/>(IBI extraction)]
        PPGpeaks --> PPGfeatures[Heart Rate & HRV Features]
    end
    subgraph ACC Signal Processing
        ACCraw([Raw Accelerometer<br/>(x,y,z axes)]) --> ACCgrav[Remove Gravity<br/>(High-pass >0.2 Hz)]
        ACCgrav --> ACCfilt[Band-limit Noise<br/>(<3 Hz)]
        ACCfilt --> ACCfeat[Movement Features<br/>(counts, intensity)]
    end
    subgraph GYR Signal Processing
        GYRraw([Raw Gyroscope<br/>(x,y,z axes)]) --> GYRfilt[Low-pass Filter<br/>(<5 Hz)]
        GYRfilt --> GYRfeat[Rotation Features<br/>(turn detection)]
    end
    %% Feature combination and classification
    PPGfeatures --> FeatureVec
    ACCfeat --> FeatureVec
    GYRfeat --> FeatureVec
    subgraph Feature Combination & Classification
        FeatureVec[Combined Feature Vector<br/>(per epoch)] --> Classify[Sleep Stage Classifier<br/>(ML/DL model)]
        Classify --> EpochLabel[Predicted Stage<br/>(per epoch)]
        EpochLabel --> Smooth[Temporal Smoothing<br/>(e.g. HMM/LSTM)]
        Smooth --> Hypnogram[Sleep Stages over Time<br/>(Hypnogram Output)]
    end
```

_Figure 1: Multi-sensor processing._ Each sensor (PPG, ACC, GYR) undergoes preprocessing (filtering, artifact removal) and feature extraction. PPG yields heart-related features (heart rate, variability), accelerometer provides motion metrics, and gyro contributes rotational movement info. These features are combined into a feature vector for each epoch, which is fed into a classifier to predict sleep stages. Post-classifier smoothing yields the final hypnogram (sleep stage timeline).

```mermaid
flowchart LR
    RawData([Raw Signals\n- PPG, ACC, GYR]) --> Preproc{{Preprocessing\n(filter, clean, segment)}}
    Preproc --> FeatExt{{Feature Extraction\n(HR/HRV, motion, etc.)}}
    FeatExt --> EpochData[Epoch Feature Set<br/>(30s windows)]
    EpochData --> ClassModel[[Classification Model]]
    ClassModel --> StageSeq[Sequence of Stage Labels]
    StageSeq --> Stats[[Sleep Metrics]]
```

_Figure 2: Hierarchical pipeline overview._ Raw wearable signals are first preprocessed (denoised and segmented), then transformed into features. Features per epoch are classified by a model, producing a sequence of sleep stage labels. Finally, sleep statistics can be derived from the classified stage sequence.

## Python Implementation Outline

To structure the processing pipeline in a hierarchical and modular way, we can design Python classes for each stage of the transformation. Below is an outline of such an implementation, demonstrating how raw data flows through preprocessing, feature extraction, and classification:

```python
import numpy as np
import scipy.signal as signal

class RawData:
    """Container for raw sensor signals and their metadata."""
    def __init__(self, ppg_signal, acc_signal, gyr_signal, fs_ppg=25, fs_acc=50, fs_gyr=50):
        self.ppg = np.array(ppg_signal)
        self.acc = np.array(acc_signal)  # shape (N,3) for 3-axis
        self.gyr = np.array(gyr_signal)  # shape (N,3)
        self.fs_ppg = fs_ppg
        self.fs_acc = fs_acc
        self.fs_gyr = fs_gyr

class PreprocessingStage:
    """Preprocess raw signals: filtering, resampling, artifact removal."""
    def __init__(self, raw_data: RawData):
        self.raw = raw_data
        # placeholders for processed outputs
        self.ppg_clean = None
        self.acc_filt = None
        self.gyr_filt = None

    def filter_ppg(self, lowcut=0.4, highcut=3.0, order=4):
        # Design a Butterworth bandpass filter and apply it (zero-phase)
        nyq = 0.5 * self.raw.fs_ppg
        b, a = signal.butter(order, [lowcut/nyq, highcut/nyq], btype='band')
        # filtfilt for zero phase filtering
        self.ppg_clean = signal.filtfilt(b, a, self.raw.ppg)
        return self.ppg_clean

    def remove_motion_artifacts_ppg(self):
        # Example: mask PPG regions with high accelerometer activity
        if self.ppg_clean is None:
            self.ppg_clean = self.raw.ppg.copy()
        acc_mag = np.linalg.norm(self.raw.acc, axis=1)  # magnitude of ACC
        # If acceleration exceeds 1g (earth gravity) by a threshold, mark artifact
        motion_mask = np.abs(acc_mag - 1.0) > 0.2  # True where motion likely
        # Simple approach: linearly interpolate PPG over motion artifact segments
        ppg = self.ppg_clean
        indices = np.arange(len(ppg))
        if motion_mask.any():
            ppg[motion_mask] = np.nan
            # interpolate NaNs
            not_nan = ~motion_mask
            self.ppg_clean = np.interp(indices, indices[not_nan], ppg[not_nan])
        return self.ppg_clean

    def filter_accelerometer(self):
        # Remove gravity (DC) component with a high-pass filter
        nyq = 0.5 * self.raw.fs_acc
        b, a = signal.butter(2, 0.2/nyq, btype='high')  # high-pass at 0.2 Hz
        acc_hp = signal.filtfilt(b, a, self.raw.acc, axis=0)
        # Optionally, low-pass to 3 Hz to remove high-frequency noise
        b2, a2 = signal.butter(4, 3.0/nyq, btype='low')
        acc_band = signal.filtfilt(b2, a2, acc_hp, axis=0)
        self.acc_filt = acc_band
        return self.acc_filt

    def filter_gyroscope(self):
        # Low-pass filter gyro to smooth out noise
        nyq = 0.5 * self.raw.fs_gyr
        b, a = signal.butter(2, 5.0/nyq, btype='low')
        self.gyr_filt = signal.filtfilt(b, a, self.raw.gyr, axis=0)
        return self.gyr_filt

    def process_all(self):
        """Run all preprocessing steps."""
        self.filter_ppg()
        self.remove_motion_artifacts_ppg()
        self.filter_accelerometer()
        self.filter_gyroscope()
        # (If needed: resample signals to common timeline here)
        return {
            'ppg': self.ppg_clean,
            'acc': self.acc_filt,
            'gyr': self.gyr_filt,
            'fs':  self.raw.fs_ppg  # choose a common fs if resampled
        }

class FeatureExtractionStage:
    """Extract features from preprocessed signals."""
    def __init__(self, processed_data: dict, epoch_len=30):
        self.ppg = processed_data['ppg']
        self.acc = processed_data['acc']
        self.gyr = processed_data['gyr']
        self.fs = processed_data.get('fs', None)  # assume unified sampling rate if provided
        self.epoch_len = epoch_len  # epoch length in seconds
        # placeholders for features
        self.hr_series = None
        self.hrv_features = []
        self.motion_features = []
        self.posture_changes = []

    def detect_peaks_ppg(self):
        # Simple peak detection using SciPy find_peaks
        dist = int(0.3 * self.fs)  # minimum distance ~0.3s * fs
        peaks, _ = signal.find_peaks(self.ppg, distance=dist, prominence=0.5) 
        return peaks

    def compute_heart_rate(self, peaks):
        # Compute instantaneous HR (BPM) from peak intervals
        if len(peaks) < 2:
            return np.array([])
        ibi = np.diff(peaks) / self.fs  # inter-beat intervals in seconds
        hr_inst = 60.0 / ibi          # instantaneous heart rate in BPM
        # create a time series at each beat (optional interpolation to uniform timeline)
        self.hr_series = hr_inst
        return hr_inst

    def compute_hrv_features(self, ibi_series):
        # Compute a set of HRV features from IBI series (in seconds)
        feats = {}
        if len(ibi_series) == 0:
            # No beats detected in window (e.g. missing data) – return NaNs
            feats.update({'HR_mean': np.nan, 'SDNN': np.nan, 'RMSSD': np.nan,
                          'pNN50': np.nan})
            return feats
        rr = ibi_series * 1000.0  # convert to ms
        # Time-domain
        diffs = np.diff(rr)
        feats['HR_mean'] = 60.0 / np.mean(ibi_series)
        feats['SDNN'] = np.std(rr)  # std dev of RR
        feats['RMSSD'] = np.sqrt(np.mean(diffs**2))
        feats['pNN50'] = np.sum(np.abs(diffs) > 50.0) / len(diffs) * 100.0  # % of differences >50ms
        # (Add frequency-domain or nonlinear features as needed)
        return feats

    def compute_motion_features(self, acc_window):
        # Simple motion features for a given window of accelerometer data
        mag = np.linalg.norm(acc_window, axis=1)
        feat = {}
        feat['activity_count'] = np.sum(np.diff(mag) > 0.1)  # count of significant changes
        feat['avg_acc'] = np.mean(mag)
        feat['max_acc'] = np.max(mag)
        return feat

    def compute_posture_change(self, acc_window_start, acc_window_end):
        # Compute orientation from average ACC at start vs end of window
        g1 = np.mean(acc_window_start, axis=0)
        g2 = np.mean(acc_window_end, axis=0)
        # angle between gravity vectors (in degrees)
        cos_angle = np.dot(g1, g2) / (np.linalg.norm(g1)*np.linalg.norm(g2))
        angle_change = np.degrees(np.arccos(np.clip(cos_angle, -1.0, 1.0)))
        return angle_change

    def extract_epoch_features(self):
        """Segment signals into epochs and extract features for each epoch."""
        if self.fs is None:
            raise ValueError("Sampling rate for unified signal not set.")
        samples_per_epoch = int(self.epoch_len * self.fs)
        total_samples = len(self.ppg)
        epoch_features = []
        for start in range(0, total_samples, samples_per_epoch):
            end = start + samples_per_epoch
            if end > total_samples:
                break  # ignore partial epoch at end
            # slice signals for this epoch
            ppg_win = self.ppg[start:end]
            acc_win = self.acc[start:end, :] if self.acc is not None else None
            gyr_win = self.gyr[start:end, :] if self.gyr is not None else None

            # Features from PPG: HR and HRV
            peaks = signal.find_peaks(ppg_win, distance=int(0.3*self.fs))[0]
            ibis = np.diff(peaks) / self.fs  # IBI in s
            hrv_feats = self.compute_hrv_features(ibis)

            # Features from motion: activity counts etc.
            motion_feats = {}
            if acc_win is not None:
                motion_feats = self.compute_motion_features(acc_win)
                # Posture change using first and second half of epoch
                mid = len(acc_win)//2
                angle_change = self.compute_posture_change(acc_win[:mid], acc_win[mid:])
                motion_feats['posture_change_deg'] = angle_change

            # Combine features
            combined = {}
            combined.update(hrv_feats)
            combined.update(motion_feats)
            # (Add more features from gyro or others if needed)
            epoch_features.append(combined)
        return epoch_features

class SleepStageClassifier:
    """Classify epochs into sleep stages using a trained model or rules."""
    def __init__(self, model=None):
        """
        model: could be a pre-trained machine learning model 
               with a predict method, or None to use rule-based.
        """
        self.model = model

    def predict_stage(self, feature_vector):
        # If a machine learning model is provided:
        if self.model is not None:
            # Assuming model has a predict or predict_proba method
            return self.model.predict([feature_vector])[0]
        # Otherwise, use a simple rule-based classification as example:
        hr = feature_vector.get('HR_mean', np.nan)
        act = feature_vector.get('activity_count', 0)
        if np.isnan(hr):
            stage = "Unknown"
        elif act > 5:   # if lots of movement
            stage = "Wake"
        elif hr < 50 and act == 0:
            stage = "Deep"
        else:
            stage = "Light/REM"  # placeholder for light or REM (would need more rules)
        return stage

    def predict_sequence(self, feature_sequence):
        stages = [self.predict_stage(feat) for feat in feature_sequence]
        # Optionally apply smoothing to stages here (e.g., merge isolated different stages)
        return stages

# --- Example usage of the pipeline ---
# raw_signals = RawData(ppg_signal=..., acc_signal=..., gyr_signal=..., fs_ppg=25, fs_acc=50, fs_gyr=50)
# preprocessor = PreprocessingStage(raw_signals)
# processed = preprocessor.process_all()
# extractor = FeatureExtractionStage(processed, epoch_len=30)
# epoch_feature_list = extractor.extract_epoch_features()
# classifier = SleepStageClassifier(model=trained_model)  # or None for rule-based
# predicted_stages = classifier.predict_sequence(epoch_feature_list)
# print(predicted_stages)  # e.g., ['Wake', 'Light', 'Light', 'Deep', ...]
```

In this code outline:

- **`RawData`** holds the raw signals and sampling rates.
- **`PreprocessingStage`** filters the PPG (bandpass), removes motion artifacts (using accelerometer data to interpolate noisy segments), filters accelerometer (high-pass to remove gravity, low-pass to reduce noise), and filters gyroscope data. The `process_all()` method returns the cleaned signals.
- **`FeatureExtractionStage`** takes the preprocessed signals and computes features. It detects PPG peaks (using `scipy.signal.find_peaks` for simplicity), computes heart rate/HRV metrics (e.g. `RMSSD`, `pNN50`), and movement features like activity count and posture change. The `extract_epoch_features()` method segments the signals into 30-second epochs and produces a list of feature dictionaries (one per epoch).
- **`SleepStageClassifier`** uses either a provided ML model or a simple heuristic to assign a sleep stage to each epoch’s feature set. In the example, a basic rule is used if no model is given (lots of movement -> Wake, low HR and no movement -> Deep, etc.). In practice, this would be replaced by a trained classifier’s prediction (e.g. `model.predict` on the feature vector).
- The example usage (commented at the bottom) demonstrates how these classes would be used in sequence to go from raw signals to predicted sleep stages.

This modular design allows swapping components (e.g., using a different peak detection method or a different classification model) and facilitates debugging at each stage (you can inspect intermediate outputs like filtered signals or extracted features).

## Deep Dive: Technical Considerations at Each Stage

With the pipeline defined, we delve deeper into the technical details of each stage, highlighting the algorithms and methodologies used to ensure accurate sleep tracking.

### 1. Raw Signal Acquisition

**PPG Sensors:** Wearable PPG is typically recorded via reflective optical sensors on the wrist. The raw PPG waveform can be very sensitive to motion and placement. _Sampling rate_ is crucial – too low and heart pulses may be missed, too high and it wastes battery with little benefit. Studies show that sampling around 25 Hz is often sufficient for heart rate estimation ([[PDF] Wearable Photoplethysmography Devices - Peter Charlton](https://peterhcharlton.github.io/publication/wearable_ppg_chapter/Wear_PPG_Chapter_20210323.pdf#:~:text=Charlton%20peterhcharlton,be%20estimated%20from%20PPG)), since the heart-rate band (0.5–4 Hz) is well-captured ([[PDF] Optical Heart Rate Monitoring (OHRM) on Wearables](https://www.ti.com/lit/SBAA564#:~:text=The%20clinical%20range%20of%20the,referred%20to%20as%20the%20pulse)). Some devices sample higher (50–100 Hz) to allow more advanced analysis or robust peak detection ([[PDF] Wearable Photoplethysmography Devices - Peter Charlton](https://peterhcharlton.github.io/publication/wearable_ppg_chapter/Wear_PPG_Chapter_20210323.pdf#:~:text=Charlton%20peterhcharlton,be%20estimated%20from%20PPG)). The raw PPG signal has a large DC component (from ambient light and steady illumination) and small pulsatile AC component (from blood volume changes). It’s good practice to log raw PPG with timestamps to allow alignment with motion signals.

**Accelerometers:** The accelerometer provides raw x, y, z acceleration readings. At rest, it measures ~1 g gravity pointing opposite to Earth’s center; any additional acceleration comes from motion. Raw accelerometer data often contains both the static gravity vector and dynamic movements. Many wearables sample ACC at 25–50 Hz for activity monitoring, which is enough to capture human motion relevant to sleep (mostly under 3 Hz) ([Sampling frequency affects the processing of Actigraph raw ...](https://journals.physiology.org/doi/10.1152/japplphysiol.00628.2015#:~:text=The%20standard%20proprietary%20algorithm%20filters,4%20software%20version)). The accelerometer data might be stored as raw counts or converted to physical units (g). Orientation of axes relative to the body is fixed by how the user wears the device (which is why consistent wearing is important).

**Gyroscopes:** The gyro outputs angular velocity about each axis. This can detect movements like arm rotations that may not produce linear acceleration spikes. For example, slowly rolling over might change orientation without a sudden acceleration (accelerometer might register it as low-frequency change, which could be filtered out, whereas gyro would see a rotation rate for the duration of the movement). Raw gyro data can drift due to bias, and unlike accelerometer, it doesn’t give an absolute reference (only changes). Some devices might not continuously log gyro for power reasons unless needed. When available, raw gyro is useful for inertial sensor fusion (e.g., combining ACC+GYR via a Kalman filter to get orientation).

**Best Practices:** Calibrate sensors if possible (e.g., zero the gyro when known to be still, or note the gravity reading on accelerometer when device is in a known flat position). Ensure synchronization of sensor streams – a common clock or timestamp is needed so PPG and ACC data align for correlation (important in artifact removal). On the user side, wearing the device snugly and in a consistent orientation (same wrist, correct sensor contact) significantly improves raw data quality ([](https://peterhcharlton.github.io/publication/wearable_ppg_chapter/Wear_PPG_Chapter_20210323.pdf#:~:text=2,can%20be%20achieved%20by%20using)).

### 2. Preprocessing Stage

The goal of preprocessing is to improve signal quality and isolate the relevant components (heart pulsations and body movements) before feature calculation.

**PPG Filtering:** A band-pass filter is applied to PPG to remove irrelevant frequencies. Low-frequency drift (<<0.5 Hz) can come from respiration, slow blood perfusion changes, or sensor drift, and high-frequency noise (>5 Hz) comes from electronics or fast hand motion. Centering around the heart rate band yields a much cleaner pulse signal ( [Robust PPG Peak Detection Using Dilated Convolutional Neural Networks - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC9414657/#:~:text=In%20addition%2C%20transform,14%20%2C%2038) ). For example, using a 4th-order Butterworth bandpass ~0.4–4 Hz can drastically improve peak detection ([Correlation analysis of heart rate variability between PPG and ECG ...](https://www.researchgate.net/publication/321411707_Correlation_analysis_of_heart_rate_variability_between_PPG_and_ECG_for_wearable_devices_in_different_postures#:~:text=,level%2C%20signal%20smoothing%2C%20and)). One study suggested 0.4–2.25 Hz as an optimal narrow band for HR estimation ([](https://peterhcharlton.github.io/publication/wearable_ppg_chapter/Wear_PPG_Chapter_20210323.pdf#:~:text=is%20beneficial%20to%20strongly%20filter,signals%20outside%20of%20this%20narrow)), excluding even the respiratory influence (which is around 0.25 Hz) to focus purely on heartbeats. However, if one plans to derive respiration from PPG, a parallel path with a low-pass filter (~0.5 Hz) might be used to isolate the breathing component ([](https://peterhcharlton.github.io/publication/wearable_ppg_chapter/Wear_PPG_Chapter_20210323.pdf#:~:text=Hz%20,55%5D.%20Consequently%2C%20wearable%20devices)). Using zero-phase filtering (forward-backward) avoids shifting the signal, which is important because any phase delay could cause misalignment between PPG peaks and actual heart beats (impacting HRV accuracy).

**Motion Artifact Removal:** Motion is the bane of PPG signals. When the user moves, the PPG sensor readings can saturate or fluctuate wildly due to changes in contact pressure or ambient light. Several techniques help mitigate this:

- _Adaptive filtering:_ Here the accelerometer signal (or its components) is used as a reference “noise” input to a filter that tries to remove motion-correlated noise from PPG ([detect and remove motion artifacts from ppg signal using lms ...](https://www.mathworks.com/matlabcentral/answers/828575-detect-and-remove-motion-artifacts-from-ppg-signal-using-lms-adaptive-filter#:~:text=detect%20and%20remove%20motion%20artifacts,be%20configured%20to%20minimize)). For instance, a least-mean-squares (LMS) adaptive filter can adjust coefficients to subtract a scaled version of ACC from PPG. This works if the motion artifact in PPG has some linear relationship with the accelerometer readings.
- _Wavelet or EMD (Empirical Mode Decomposition):_ These methods decompose the PPG signal into multiple frequency bands or intrinsic mode functions. Motion artifact often shows up as specific patterns that can be separated. For example, a wavelet-based approach might isolate the cardiac component at certain scales while separating motion artifact into another scale ([Frontiers | Motion Artifact Removal Techniques for Wearable EEG and PPG Sensor Systems](https://www.frontiersin.org/journals/electronics/articles/10.3389/felec.2021.685513/full#:~:text=wavelet%20transform%20%28I,respiratory%20data%20can%20be%20restored)). One study used a dual-tree complex wavelet transform and independent component analysis (ICA) to remove motion while preserving the respiratory oscillation in PPG ([Frontiers | Motion Artifact Removal Techniques for Wearable EEG and PPG Sensor Systems](https://www.frontiersin.org/journals/electronics/articles/10.3389/felec.2021.685513/full#:~:text=wavelet%20transform%20%28I,respiratory%20data%20can%20be%20restored)).
- _Simple thresholding:_ A practical approach is to detect when motion is too high (using accelerometer magnitude or PPG signal variance) and then either discard or not trust the PPG-derived features during those periods ([](https://peterhcharlton.github.io/publication/wearable_ppg_chapter/Wear_PPG_Chapter_20210323.pdf#:~:text=2,can%20be%20achieved%20by%20using)). Some wearables effectively do this by pausing HR measurements when the user moves a lot, because the data would be unreliable ([](https://peterhcharlton.github.io/publication/wearable_ppg_chapter/Wear_PPG_Chapter_20210323.pdf#:~:text=2,can%20be%20achieved%20by%20using)).
- _Smoothing_: If only mild artifact is present, a moving average or morphological filter on PPG can suppress spikes. Also, interpolation as shown in the code (setting artifact segments to NaN and interpolating) is a straightforward way to avoid false peaks.

**Accelerometer Filtering:** Raw accelerometer includes gravity (~1 g constant) plus motion. For sleep analysis, the gravity component can actually be useful (to detect orientation), but often we separate it for certain features. A common approach is splitting into:

- DC component (gravity): by low-pass filtering at ~0.2–0.3 Hz (since posture changes happen slowly, over many seconds).
- AC component (motion): by high-pass filtering at ~0.2–0.3 Hz ([Sampling frequency affects the processing of Actigraph raw ...](https://journals.physiology.org/doi/10.1152/japplphysiol.00628.2015#:~:text=The%20standard%20proprietary%20algorithm%20filters,4%20software%20version)). This AC part represents quick movements. Many actigraphy algorithms effectively apply such a filter; the standard ActiGraph count algorithm band-passes 0.25–2.5 Hz ([Sampling frequency affects the processing of Actigraph raw ...](https://journals.physiology.org/doi/10.1152/japplphysiol.00628.2015#:~:text=The%20standard%20proprietary%20algorithm%20filters,4%20software%20version)), which removes the static gravity and very fast noise, focusing on typical human activity frequencies.
- After filtering, one often computes the **vector magnitude** = √(x²+y²+z²) minus 1 g (to subtract gravity if DC removed) as an aggregate measure of movement intensity. This simplifies further processing to one time-series of “overall movement”.

**Gyroscope Preprocessing:** Gyro data tends to be high-pass in nature (no gravity component, since it measures change). It mostly needs smoothing to remove sensor noise. A low-pass at a few Hz is usually fine because most relevant rotations (turning over in bed, arm movements) are not very high frequency. Additionally, because gyro measures angular velocity, integrating it gives change in angle; however, integration can introduce drift error. High-pass filtering accelerometer and low-pass filtering gyro are complementary steps often used in sensor fusion to get tilt and motion.

**Resampling and Sync:** If PPG and ACC have different sampling rates, after filtering, we might resample one to align with the other or at least align to epoch boundaries. For example, one could resample PPG to 50 Hz to match ACC, or vice versa, or simply compute features separately and sync by time. Ensuring both modalities refer to the exact same epoch times is crucial for combined feature analysis.

**Quality Checks:** Preprocessing is a good stage to implement signal quality indices. For instance, one can flag an epoch if PPG had too few detected peaks or if >50% of it was interpolated due to motion. This flag can later be used to adjust classification (e.g., rely more on ACC if PPG quality was poor in that epoch).

### 3. Feature Extraction Stage

After cleaning the signals, we extract meaningful features that correlate with sleep physiology.

**Heart Rate and Variability:** From PPG, the primary features are related to heart rate:

- **Instantaneous heart rate (HR)** – can be averaged per epoch, or one can use the full sequence of RR intervals (IBIs) as input to more sophisticated models. Heart rate tends to be higher during REM and wake, and lower during deep sleep, with a gradual decline in the first hours of sleep and some rises during REM.
- **Heart Rate Variability (HRV)** – reflects the balance of sympathetic and parasympathetic nervous system. During deep slow-wave sleep, parasympathetic (vagal) activity dominates, often increasing HRV (high RMSSD, high pNN50, etc.), whereas during REM, the autonomic state can be more mixed or sympathetic, often reducing HRV ([Heart Rate Variability and Sleep - Amerisleep](https://amerisleep.com/blog/heart-rate-variability-and-sleep/#:~:text=Heart%20Rate%20Variability%20and%20Sleep,you%20cycle%20through%20the)). Many studies use HRV features to differentiate REM vs non-REM especially ( [Sleep stage classification from heart-rate variability using long short-term memory neural networks - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC6775145/#:~:text=Automated%20sleep%20stage%20classification%20using,R%26K) ). Common features:
    - Time-domain: SDNN (standard deviation of NN intervals), RMSSD (root mean square of successive differences), pNN50 (% of differences >50ms), etc.
    - Frequency-domain: typically requires a longer window. Sometimes 5-minute windows are used to compute low-frequency (LF) and high-frequency (HF) band power of HRV. However, some researchers attempt approximate spectral features even on shorter epochs (e.g. by Welch periodogram on a 1-2 min sliding window of RR intervals).
    - Nonlinear: entropy measures, Poincaré plot metrics (SD1, SD2), etc. These can capture complexity of heart rate dynamics.
- **Pulse morphology**: While not common in wearables for sleep, one could extract features like pulse amplitude, pulse transit time (if there’s a reference like a foot sensor or using ACC to detect ballistocardiogram, but on wrist this is not straightforward). Mostly, HR and HRV suffice.

It’s worth noting that PPG-derived HRV (sometimes called PRV – pulse rate variability) is very similar to ECG-derived HRV in low-movement conditions ( [It is All in the Wrist: Wearable Sleep Staging in a Clinical Population versus Reference Polysomnography - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC8253894/#:~:text=autonomic%20activity%20are%20often%20captured,cardiac%20activity%20and%2C%20in%20addition) ). In sleep, assuming the person is mostly still, PPG HRV is a reasonable surrogate for ECG HRV ( [It is All in the Wrist: Wearable Sleep Staging in a Clinical Population versus Reference Polysomnography - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC8253894/#:~:text=earlier%20work%2C%20but%20while%20in,scored%20sleep%20stages%20from%20PSG) ). One validation study used PPG HRV and got comparable sleep staging accuracy to ECG HRV models ( [It is All in the Wrist: Wearable Sleep Staging in a Clinical Population versus Reference Polysomnography - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC8253894/#:~:text=earlier%20work%2C%20but%20while%20in,scored%20sleep%20stages%20from%20PSG) ).

**Respiratory Features:** If respiration is extracted (from PPG or ACC), it can provide additional insight. For example, **respiratory rate** tends to be slower and very regular in deep NREM sleep, and becomes more irregular and faster in REM (where breaths can vary and there may be transient cessations or irregular patterns). Some algorithms look at the _respiratory sinus arrhythmia (RSA)_ – the HRV component at the respiration frequency (i.e., how heart rate oscillates with breathing). RSA is typically strong in deep sleep (high vagal tone). A change in RSA or breathing irregularity might signal REM. If the device is a chest strap or a smart bed, direct respiratory signals are used. With a wrist-worn device, respiratory extraction is indirect; techniques include:

- Band-pass filtering the PPG at 0.1–0.3 Hz to get the baseline wander which corresponds to breathing ([Frontiers | Motion Artifact Removal Techniques for Wearable EEG and PPG Sensor Systems](https://www.frontiersin.org/journals/electronics/articles/10.3389/felec.2021.685513/full#:~:text=wavelet%20transform%20%28I,respiratory%20data%20can%20be%20restored)).
- Using accelerometer on the chest (some wearables have a sensor you can stick to the torso) or even on the mattress to detect breathing movements.
- Utilizing the frequency modulation of the PPG peak interval or amplitude by breathing (when you inhale, intrathoracic pressure changes cause subtle HR changes and amplitude changes in PPG). These features are more experimental in wearables but can enhance stage classification if accurate.

**Activity and Movement:** The accelerometer yields various measures of movement:

- **Activity count**: as described, a combined value representing the amount of motion in an epoch. Many commercial sleep trackers essentially threshold this count to decide wake vs sleep. If count = 0 for a prolonged time, it’s likely sleep; if consistently high, likely wake. For multi-stage, a low count period could be any of the sleep stages, so we need HRV to further distinguish those.
- **Movement intensity**: features like average acceleration or maximum acceleration in epoch can differentiate light tosses versus a strong movement (e.g. sitting up).
- **Number of movements**: e.g. how many distinct movement bouts in an epoch. REM can often have sudden twitches separated by stillness, so number of distinct bursts might be a feature.
- **Orientation/posture**: If a person goes from lying on back to side, the device orientation changes. If we detect a significant orientation change, that epoch might coincide with a brief awakening or lighter sleep. Even if the person doesn’t fully wake, large body movements usually indicate at least arousal from deep sleep. As a feature, “posture change = yes/no” in epoch could indicate lighter sleep. Conversely, long periods with no posture change might indicate stable sleep (though could also just be someone who doesn’t move much).
- **Gyro-based**: The gyro could detect small rotations like hand tilting (maybe indicating conscious adjustment or REM-related muscle twitches if any). However, in many cases, accelerometer magnitude features capture enough.

**Feature Engineering:** The combination of features is important. For instance, computing the **standard deviation of heart rate over the epoch** was found useful in one study ( [Sleep stage prediction with raw acceleration and photoplethysmography heart rate data derived from a consumer wearable device - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC6930135/#:~:text=Watch%20worn%20by%20participants%20undergoing,when%20all) ) – it’s effectively a short-term HRV measure (if heart rate fluctuates a lot within 30s, maybe a sign of arousal). That study by Walch et al. included _“local standard deviation of heart rate”_ as a feature and a “clock proxy” (time of day) ( [Sleep stage prediction with raw acceleration and photoplethysmography heart rate data derived from a consumer wearable device - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC6930135/#:~:text=Watch%20worn%20by%20participants%20undergoing,when%20all) ), which improved classification by giving context of where in the night the epoch is. Including time-of-night or time-since-sleep-onset is a clever way to allow the model to learn that, for example, REM is more likely in the early morning, whereas deep sleep is more likely in the first third of the night.

When extracting a large number of features (like 100+), one might do dimensionality reduction or feature selection. But some approaches (like gradient boosting or random forest) handle many features and figure out importance automatically. Simpler models might need a reduced feature set to avoid overfitting.

It’s also common to take **rolling statistics**: e.g., not just features within the epoch, but over a window of epochs. For example, average heart rate in the last 5 minutes, or variance of acceleration over last 10 minutes, etc. This bleeds into the temporal analysis stage.

### 4. Temporal Analysis Stage

Sleep stages are inherently temporal sequences – they follow a progression and have duration. Simply classifying each epoch independently can lead to jagged stage sequences that are physiologically implausible (e.g., jumping from Wake to Deep for one epoch and back to Wake, etc.). Temporal analysis tries to enforce some consistency.

**Epoch Selection:** As noted, 30 seconds is standard ( [An automated heart rate-based algorithm for sleep stage classification: Validation using conventional polysomnography and an innovative wearable electrocardiogram device - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC9584568/#:~:text=This%20validation%20study%20highlights%20the,simultaneous%20PSG%20collection%20using%20SOMNOtouch) ). Using the standard epoch means any comparison to ground truth PSG is direct, since PSG is scored in 30s epochs. If we used a different epoch length, we’d have to aggregate or break down PSG which complicates validation. Some consumer devices report minute-by-minute, which might just be an averaged or majority vote of two 30s epochs internally.

**Sliding Window vs Fixed Epoch:** Some algorithms use a sliding window (e.g. a new prediction every 15s but looking at the past 60s of data) to get finer resolution. This can be beneficial for capturing transitions more promptly. The pipeline above assumes fixed non-overlapping epochs for simplicity.

**Sequence Modeling:** There are a few ways to incorporate sequence information:

- **Feature Smoothing:** Compute features over a longer window or include history. For example, you might append features from the previous epoch (or a few previous) as additional inputs to the classifier for the current epoch.
- **Hidden Markov Model (HMM):** Use the output of an initial classifier as observations and define hidden states as true sleep stages. The HMM can then impose transition probabilities (which could be learned from data or set according to known physiology). For instance, an HMM might learn that the probability of going from Wake to REM directly is very low, so it will favor going Wake -> Light -> REM in sequence. HMMs were used in older actigraphy algorithms to improve sleep/wake detection by modeling the binary state sequence ([A hidden Markov modeling approach combining objective measure ...](https://pmc.ncbi.nlm.nih.gov/articles/PMC10810673/#:~:text=,measures%20to%20estimate)).
- **Conditional Random Field or other sequence models** can be used similarly to HMM but allow more flexible inclusion of features.
- **Recurrent Neural Networks:** Modern approaches use RNNs like LSTM that take a sequence of feature vectors (for consecutive epochs) and output a sequence of stage predictions. The LSTM can learn the typical durations and transitions implicitly. In fact, the referenced study by Van Steenkiste et al. (2019) used an LSTM on a sequence of HRV features and reached ~77% accuracy 4-class ( [Sleep stage classification from heart-rate variability using long short-term memory neural networks - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC6775145/#:~:text=methods%20however%20are%20limited%20in,00) ), showing the power of modeling the temporal context.
- **Multi-pass classification:** Another approach is a hierarchical classification: first classify epochs coarsely (e.g., sleep vs wake), then in a second pass refine the sleep epochs into light/deep/REM. This can use the knowledge of contiguous sleep periods. For example, once you identify a contiguous block of “sleep” epochs, you could post-process that block with a separate classifier to label REM vs NREM stages.

**Smoothing and Corrections:** Even after classification, a common practice is to apply a smoothing filter on the predicted labels. For instance, a median filter of length 3 will remove one-epoch outliers (if you have Deep, Light, Deep, it would become Deep, Deep, Deep which might be more plausible if that middle Light was a misclassification). Some algorithms enforce that REM must have some minimum duration or that stage changes can’t be too frequent. However, over-smoothing can hide real brief arousals or stage shifts, so it’s a balance.

**Circadian Context:** The “clock proxy” feature included by some (the time into recording or time of night) is an interesting temporal context inclusion ( [Sleep stage prediction with raw acceleration and photoplethysmography heart rate data derived from a consumer wearable device - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC6930135/#:~:text=Watch%20worn%20by%20participants%20undergoing,when%20all) ). By giving the model a sense of how far along the night it is, it can learn expectations (like REM-rich later cycles vs deep early). This isn’t a dynamic model per se, but it embeds time as a feature in each epoch’s feature vector.

### 5. Aggregation & Classification Stage

Finally, the classification stage assigns sleep stages based on the features (and possibly their temporal context).

**Combining Modalities:** Before classification, we have to combine PPG-derived and ACC/gyro-derived features. This sensor fusion at the feature level is straightforward (just concatenate features). An alternative is decision-level fusion (e.g., have one classifier for ACC that decides sleep/wake, another for PPG that decides a stage, then combine rules). But most modern approaches feed all features into one model to let it decide. The success of combining PPG with ACC is documented – e.g., one large study found that using both gives much better multi-stage differentiation than ACC alone ( [Evaluating reliability in wearable devices for sleep staging - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC10948771/#:~:text=from%20the%20past%20decade%2C%20evaluating,performance%20analysis%20of%20commercial%20algorithms) ).

**Model Choice:** The table and pipeline outline several model types:

- _Heuristic Rules:_ Earlier generation devices often used fixed rules (if movement > X, mark wake, etc.). These are easy to implement and computationally trivial (important for wearables with limited CPU). They work OK for sleep vs wake (since actigraphy is well-studied there) but cannot reliably distinguish stages like REM vs light sleep because those both have low movement.
- _Classical ML:_ Many academic studies train classifiers like Random Forests, SVMs, or XGBoost on features. These have the advantage of being trainable on relatively small datasets and providing some insight into feature importance. For example, XGBoost was used in a study combining PPG HRV and accelerometer, achieving good accuracy in 3-class staging ([Automation of classification of sleep stages and estimation of sleep ...](https://pmc.ncbi.nlm.nih.gov/articles/PMC9869419/#:~:text=,related%20features%20and%20acceleration%20features)). Random Forest might show that, say, RMSSD and activity count are among top predictors for deep sleep.
- _Neural Networks:_ Deep learning can take two forms:
    1. Feed-forward networks on the features – essentially replacing something like an SVM with a multi-layer perceptron. This doesn’t fully leverage time dependencies unless you feed time features.
    2. CNNs on raw signals – some experiments use 1D CNN to directly process the raw or filtered PPG and ACC signals over an epoch, letting the network learn feature extraction. This requires more data and is less interpretable but could capture patterns like specific waveform shapes. For instance, a CNN might learn to pick up on the slight respiratory modulation in the PPG that correlates with deep sleep.
    3. Recurrent networks (LSTM) – as discussed, these handle sequences. Some approaches combine CNN and LSTM: e.g., CNN to process short-term signals to features, then LSTM to model the sequence of those for the whole night.
- _Multi-level models:_ A referenced approach used a multi-level classification – first binary (sleep/wake) with one algorithm, then within the sleep epochs classify REM vs NREM with another, possibly splitting NREM into deep vs light with yet another layer ([A Multi-Level Classification Approach for Sleep Stage Prediction ...](https://www.frontiersin.org/journals/digital-health/articles/10.3389/fdgth.2021.665946/full#:~:text=A%20Multi,SVM%29%20with%20linear)). This can sometimes simplify the learning task at each step.

**Training Considerations:** Regardless of model, training data needs to be labeled by polysomnography (EEG-based staging). That is the ground truth for sleep stages. Training on enough individuals is key for generalization – wearables often show degraded accuracy in populations not represented in training (e.g., people with certain conditions, or children if only adults were in training). Cross-validation and eventually independent validation (preferably on data from a different study or device) are needed, as emphasized in literature ( [An automated heart rate-based algorithm for sleep stage classification: Validation using conventional polysomnography and an innovative wearable electrocardiogram device - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC9584568/#:~:text=The%20rapid%20advancement%20in%20wearable,PSG) ) ( [An automated heart rate-based algorithm for sleep stage classification: Validation using conventional polysomnography and an innovative wearable electrocardiogram device - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC9584568/#:~:text=This%20validation%20study%20highlights%20the,simultaneous%20PSG%20collection%20using%20SOMNOtouch) ).

**Performance:** To gauge performance, common metrics are overall accuracy and Cohen’s kappa (agreement with PSG). Typical results for multi-class (Wake, Light, Deep, REM) with PPG+ACC are around 0.60–0.70 kappa ( [It is All in the Wrist: Wearable Sleep Staging in a Clinical Population versus Reference Polysomnography - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC8253894/#:~:text=Results) ), which is considered “substantial agreement” but not perfect. Accuracy might be ~75% ( [It is All in the Wrist: Wearable Sleep Staging in a Clinical Population versus Reference Polysomnography - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC8253894/#:~:text=Results) ), which sounds high but note that if ~20-25% of epochs are wake and mostly at beginning/end, a model can boost accuracy by correctly labeling the large majority of sleep epochs. So kappa is a better measure because it accounts for the imbalance and agreement by chance. For 3-class (Wake, NREM, REM), accuracy can reach ~80%+ in some cases ( [An automated heart rate-based algorithm for sleep stage classification: Validation using conventional polysomnography and an innovative wearable electrocardiogram device - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC9584568/#:~:text=This%20validation%20study%20highlights%20the,simultaneous%20PSG%20collection%20using%20SOMNOtouch) ). For binary (sleep vs wake), actigraphy algorithms typically get 85–95% sensitivity for sleep, but lower specificity for wake (since it’s easy to mis-score quiet wake as sleep) ( [Sleep stage prediction with raw acceleration and photoplethysmography heart rate data derived from a consumer wearable device - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC6930135/#:~:text=performance%20was%20achieved%20using%20neural,for%20the%20first%20time%2C%20the) ).

**Hybrid Approaches:** Some commercial solutions blend rule-based and ML. For instance, they might use ML to classify most epochs but if the confidence is low or something unusual is detected, they apply some rules or fallbacks. The pipeline can be made adaptive too – e.g., if PPG signal quality is poor one night, rely more on ACC features. These considerations go beyond static classification into making the system robust for real-life usage.

**Output and User Feedback:** The final output is usually a hypnogram (stage vs time) and aggregate metrics (sleep duration, time in REM, etc.). It’s important that all the transformations feed correctly into these outputs. For example, if the classifier misidentifies REM as wake often, the user might get a lower “sleep efficiency” or weird sleep graphs. Continuous improvement and validation on edge cases (like people with arrhythmia, or those who read in bed without moving which could confuse ACC-only logic) are necessary.

### Summary

By applying this hierarchical pipeline – from raw PPG/accelerometer/gyro signals, through careful preprocessing (filtering noise and removing artifacts), extracting physiological features (heart rate variability, motion counts, etc.), analyzing temporal patterns, and finally using a classification model – wearable devices can automatically infer sleep stages with reasonable accuracy. Each stage uses well-established signal processing and machine learning techniques, many of which have roots in clinical research (e.g. HRV analysis, actigraphy, sleep medicine). The provided table, diagrams, and code illustrate how these pieces come together. According to studies, combining cardiac and motion signals is crucial for multi-stage sleep tracking ( [Evaluating reliability in wearable devices for sleep staging - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC10948771/#:~:text=from%20the%20past%20decade%2C%20evaluating,performance%20analysis%20of%20commercial%20algorithms) ), and advanced algorithms (like deep learning on HRV sequences) show promise in closing the gap with traditional sleep monitoring ( [Sleep stage classification from heart-rate variability using long short-term memory neural networks - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC6775145/#:~:text=541,based%20sleep%20stage%20classification.%20Further) ). As always, thorough validation and iterative refinement of these algorithms, guided by domain knowledge and data, are key to a reliable sleep tracking system.

## References

- Wulterkens et al., _"It is All in the Wrist: Wearable Sleep Staging in a Clinical Population versus Reference Polysomnography"_ – **PMID:** 34234595. (Demonstrated a PPG+accelerometer algorithm with ~76% accuracy 4-class, using HRV features and an LSTM classifier) ( [It is All in the Wrist: Wearable Sleep Staging in a Clinical Population versus Reference Polysomnography - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC8253894/#:~:text=Results) ) ( [It is All in the Wrist: Wearable Sleep Staging in a Clinical Population versus Reference Polysomnography - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC8253894/#:~:text=built%20and%20used%20as%20input,axial%20accelerometer) ) ( [It is All in the Wrist: Wearable Sleep Staging in a Clinical Population versus Reference Polysomnography - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC8253894/#:~:text=The%20combined%20HRV%20and%20body,outputs%20the%20posterior%20probability%20for) ).
- Walch et al., _"Sleep Stage Prediction with Raw Acceleration and Photoplethysmography Heart Rate Data from a Consumer Wearable"_ – **PMCID:** PMC6930135. (Used Apple Watch data with features like motion, HR variability, and time-of-night in various classifiers, achieving ~72% accuracy for Wake/NREM/REM) ( [Sleep stage prediction with raw acceleration and photoplethysmography heart rate data derived from a consumer wearable device - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC6930135/#:~:text=contributions%20of%20multiple%20features%20,ethnic%20Study%20of%20Atherosclerosis) ) ( [Sleep stage prediction with raw acceleration and photoplethysmography heart rate data derived from a consumer wearable device - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC6930135/#:~:text=contributions%20of%20multiple%20features%20,wake%20classification%2C%20our%20method) ).
- van Steenkiste et al., _"Automated sleep stage classification using HRV and LSTM networks"_ – **PMCID:** PMC6775145. (Validated that deep learning on heart rate variability sequences can reach ~77% accuracy in multi-stage classification, highlighting the importance of long-term temporal context) ( [Sleep stage classification from heart-rate variability using long short-term memory neural networks - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC6775145/#:~:text=methods%20however%20are%20limited%20in,00) ) ( [Sleep stage classification from heart-rate variability using long short-term memory neural networks - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC6775145/#:~:text=541,based%20sleep%20stage%20classification.%20Further) ).
- Mirek et al., _"Evaluating reliability in wearable devices for sleep staging – scoping review"_ – **PMCID:** PMC10948771. (Reviewed 35 studies; noted trend that combining accelerometer with PPG improves multi-stage classification vs accelerometer alone) ( [Evaluating reliability in wearable devices for sleep staging - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC10948771/#:~:text=from%20the%20past%20decade%2C%20evaluating,performance%20analysis%20of%20commercial%20algorithms) ).
- Charlton et al., _"Wearable Photoplethysmography Devices"_ – arXiv:2103.10551. (Comprehensive review of PPG signal processing; recommends bandpass ~0.4–2.5 Hz for HR extraction and discusses power-saving via activity-informed sampling) ([](https://peterhcharlton.github.io/publication/wearable_ppg_chapter/Wear_PPG_Chapter_20210323.pdf#:~:text=is%20beneficial%20to%20strongly%20filter,signals%20outside%20of%20this%20narrow)) ([](https://peterhcharlton.github.io/publication/wearable_ppg_chapter/Wear_PPG_Chapter_20210323.pdf#:~:text=2,can%20be%20achieved%20by%20using)).
- Rezek et al., _"Robust PPG Peak Detection Using Dilated CNNs"_, IEEE JBHI 2022 – **PMCID:** PMC9414657. (Summarizes traditional peak detection: adaptive thresholds, wavelet transforms, etc., and proposes a CNN for PPG peak detection under motion) ( [Robust PPG Peak Detection Using Dilated Convolutional Neural Networks - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC9414657/#:~:text=are%20commonly%20used%20for%20peak,12) ) ( [Robust PPG Peak Detection Using Dilated Convolutional Neural Networks - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC9414657/#:~:text=In%20addition%2C%20transform,14%20%2C%2038) ).
- Frontiers in Electronics, _"Motion Artifact Removal Techniques for Wearable EEG and PPG"_ 2021. (Provides an overview of methods like regression, adaptive filtering, and wavelet-ICA for removing motion artifacts in biosignals) ([Frontiers | Motion Artifact Removal Techniques for Wearable EEG and PPG Sensor Systems](https://www.frontiersin.org/journals/electronics/articles/10.3389/felec.2021.685513/full#:~:text=wavelet%20transform%20%28I,respiratory%20data%20can%20be%20restored)).
- Actigraphy algorithms review by Błoński et al. 2021, _"On the Unification of Common Actigraphic Data Scoring Algorithms"_ – **PMCID:** PMC8472753. (Analyzes algorithms like Cole-Kripke, showing they are effectively specialized filters on acceleration signals) ( [On the Unification of Common Actigraphic Data Scoring Algorithms - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC8472753/#:~:text=applications%20of%20actigraphy,Proposed%20framework%20provides%20a%20robust) ).
- Frontiers in Neurosci., _"Heart rate-based sleep staging algorithm validation"_ 2022 – **PMCID:** PMC9584568. (Validated a deep learning algorithm using just heart rate/HRV for 4-stage classification on large datasets, highlighting the potential of HR signals alone) ( [An automated heart rate-based algorithm for sleep stage classification: Validation using conventional polysomnography and an innovative wearable electrocardiogram device - PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC9584568/#:~:text=Materials%20and%20methods) ).