# Polar Workflow Example with relative paths and file patterns
# This workflow demonstrates importing heart rate and accelerometer data 
# from Polar H10 and Sense sensors, and exporting to CSV
#
# To run:
# python -m sleep_analysis.cli.run_workflow --workflow workflows/polar_workflow.yaml --data-dir data

# Timezone settings
default_input_timezone: "America/New_York" # Assume source files are EST unless overridden
target_timezone: "system" # Standardize all timestamps to the system's local timezone

# Collection-level settings (applied before import/steps)
collection_settings:
  index_config: ["signal_type", "sensor_model", "body_position", "name"]
  epoch_grid_config: # Global settings for feature epoch grid
    window_length: "30s" # Default window length for features
    step_size: "15s"     # Step size defines epoch start frequency


import:
  # Heart Rate data from Polar H10 - using MergingImporter
  - signal_type: "heart_rate"
    importer: "MergingImporter"
    source: "."
    config:
      file_pattern: "Polar_H10_*_HR.txt"
      timestamp_col: "Phone timestamp"
      sort_by: "timestamp"
      delimiter: ";"
      column_mapping:
        timestamp: "Phone timestamp"
        hr: "HR [bpm]"
        hrv: "HRV [ms]"
        hrv: "HRV [ms]"
    sensor_type: "EKG"
    sensor_model: "PolarH10"
    body_position: "chest"
    name: "H10_HR"
    base_name: "hr"


  # Accelerometer data from Polar H10 - using MergingImporter
  - signal_type: "accelerometer"
    importer: "MergingImporter"
    source: "."
    config:
      file_pattern: "Polar_H10_*_ACC.txt"
      timestamp_col: "Phone timestamp"
      sort_by: "timestamp"
      delimiter: ";"
      column_mapping:
        timestamp: "Phone timestamp"
        x: "X [mg]"
        y: "Y [mg]"
        z: "Z [mg]"
    sensor_type: "ACCEL"
    sensor_model: "PolarH10"
    body_position: "chest"
    name: "H10_ACC"
    base_name: "accel"
    

  # Heart Rate data from Polar Sense - using MergingImporter
  - signal_type: "heart_rate"
    importer: "MergingImporter"
    source: "."
    config:
      file_pattern: "Polar_Sense_*_HR.txt"
      timestamp_col: "Phone timestamp"
      sort_by: "timestamp"
      delimiter: ";"
      column_mapping:
        timestamp: "Phone timestamp"
        hr: "HR [bpm]"
    sensor_type: "EKG"
    sensor_model: "PolarSense"
    body_position: "left_wrist"
    name: "Sense_HR"
    base_name: "hr"
    


  # Accelerometer data from Polar Sense - using MergingImporter
  - signal_type: "accelerometer"
    importer: "MergingImporter"
    source: "."
    config:
      file_pattern: "Polar_Sense_*_ACC.txt"
      timestamp_col: "Phone timestamp"
      sort_by: "timestamp"
      delimiter: ";"
      column_mapping:
        timestamp: "Phone timestamp"
        x: "X [mg]"
        y: "Y [mg]"
        z: "Z [mg]"
    sensor_type: "ACCEL"
    sensor_model: "PolarSense"
    body_position: "left_wrist"
    name: "Sense_ACC"
    base_name: "accel"


  # EEG Sleep Stage data from Enchanted Wave - using MergingImporter
  - signal_type: "eeg_sleep_stage"
    importer: "MergingImporter" # Use MergingImporter to handle potential multiple files
    source: "."
    config:
      # Configuration for the underlying importer (EnchantedWaveImporter)
      importer_name: "EnchantedWaveImporter"
      file_pattern: "*.Session.csv" # Pattern to find Enchanted Wave files
      # EnchantedWaveImporter uses default column mapping, no need to specify here unless overriding
      # Override the default_input_timezone for this specific source
      origin_timezone: "UTC" # Assume this specific source file is in UTC
    sensor_type: "EEG"
    sensor_model: "EnchantedWave"
    body_position: "head"
    name: "EnchantedWave_SleepStage"
    base_name: "sleep_stage"


# Process steps to compute magnitude signals and align everything
steps:
  # Generate magnitude signals from all accelerometer signals
  - type: signal
    input: "accel"  # Base name for all accelerometer signals
    operation: "compute_magnitude"
    output: "accel_magnitude"
    
  # Generate angle signals from all accelerometer signals
  - type: signal
    input: "accel"  # Base name for all accelerometer signals
    operation: "compute_angle"
    output: "accel_angle"

  # Step 1: Calculate alignment grid parameters
  - type: collection
    operation: "generate_alignment_grid"
    parameters:
      target_sample_rate: 10.0  # Optional: Specify target rate (Hz). If omitted, uses max standard rate <= highest signal rate.

  # Step 2: Apply the calculated alignment grid to all time-series signals in place
  - type: collection
    operation: "apply_grid_alignment"
    parameters:
      method: "nearest" # Method used by _reindex_to_grid_logic

  # Step 3: Combine the modified (snapped) signals using outer join + reindex
  # This reads the modified signals and creates the final combined dataframe.
  - type: collection
    operation: "combine_aligned_signals"
    parameters: {} # No parameters needed

  # --- Feature Extraction Steps ---
  # Prerequisite: generate_alignment_grid and apply_grid_alignment must have run

  # Step 4: Generate the common epoch grid for all feature extraction steps
  # This uses the epoch_grid_config defined in collection_settings
  - type: collection
    operation: "generate_epoch_grid"
    parameters: {} # Optional: start_time, end_time overrides

  # Step 5: Compute basic statistics for Heart Rate signals
  - type: multi_signal # Assuming feature ops are registered in multi_signal_registry
    operation: "feature_statistics"
    inputs: ["hr"] # Use base name to get all HR signals
    parameters:
      # window_length: "30s" # Optional: Uses global "30s" from epoch_grid_config if omitted
      # step_size: "10s"     # REMOVED: Step size is now global, defined by epoch_grid_index
      aggregations: ["mean", "std", "min", "max"]
    output: "hr_features" # Base name for HR feature signals

  # Step 6: Compute basic statistics for Accelerometer Magnitude signals
  - type: multi_signal
    operation: "feature_statistics"
    inputs: ["accel_magnitude"] # Use base name
    parameters:
      # window_length: "30s" # Optional: Uses global
      # step_size: "10s"     # REMOVED
      aggregations: ["mean", "std"]
    output: "accel_mag_features"

  # Step 7: Compute basic statistics for Accelerometer Angle signals (e.g., pitch/roll)
  # Assuming 'accel_angle' contains columns like 'pitch', 'roll'
  - type: multi_signal
    operation: "feature_statistics"
    inputs: ["accel_angle"] # Use base name
    parameters:
      # window_length: "30s" # Optional: Uses global
      # step_size: "10s"     # REMOVED
      aggregations: ["mean", "std"] # Apply to pitch, roll etc.
    output: "accel_angle_features"

  # Step 8: Compute features for Sleep Stage signals
  # NOTE: feature_statistics currently calculates numeric stats (mean, std).
  # Applying this to categorical sleep stages might not be ideal.
  # Consider implementing a dedicated feature operation (e.g., mode, stage fractions).
  # Step 8: Compute mode feature for Sleep Stage signals
  - type: multi_signal
    operation: "compute_sleep_stage_mode" # <--- Use the new operation
    inputs: ["sleep_stage"] # Use base name for EnchantedWave_SleepStage
    parameters: {} # <--- No aggregations needed for mode
    output: "sleep_stage_mode" # <--- Updated output name

  # Step 9: Combine all generated feature signals into a single matrix
  - type: collection
    operation: "combine_features"
    inputs: ["hr_features", "accel_mag_features", "accel_angle_features", "sleep_stage_mode"] # <--- Use the updated feature key
    # output: "final_features" # REMOVED: combine_features stores result internally
    parameters: {} # No parameters needed currently

  # Step 10: Generate and store a summary of all signals in the collection
  - type: collection
    operation: "summarize_signals"
    parameters:
      # Optional: Specify exact fields to include in the stored summary DataFrame
      # fields_to_include: ["signal_type", "name", "sample_rate", "data_shape"]
      # Optional: Control printing of the formatted summary to console (default is true)
      print_summary: true

# Export section - defines the output formats and location
# The exporter can retrieve the combined dataframe and/or the summary dataframe
# index_config moved to collection_settings
export:
  # Export ONLY the combined aligned time-series data
  - formats: ["csv"]
    output_dir: "results/polar_data/aligned_timeseries"
    content: ["combined_ts"] # Explicitly request combined time series

  # Export ONLY the final combined feature matrix and the summary table
  - formats: ["csv", "excel"]
    output_dir: "results/polar_data/features_and_summary"
    content: ["combined_features", "summary"] # Explicitly request combined features and summary

  # Export ONLY all individual non-temporary TimeSeriesSignals to CSV
  - formats: ["excel"]
    output_dir: "results/polar_data/individual_timeseries"
    content: ["all_ts"] # Explicitly request all individual time series

  # Export ONLY all individual Features to Excel
  - formats: ["excel"]
    output_dir: "results/polar_data/individual_features"
    content: ["all_features"] # Explicitly request all individual features

  # Export specific signals/features by key
  - formats: ["pickle"]
    output_dir: "results/polar_data/specific_items"
    content: ["hr_0", "accel_mag_features"] # Corrected key: Use _0 for the first feature

  # Example: Export individual TS AND combined features in one task
  - formats: ["csv"]
    output_dir: "results/polar_data/individual_ts_and_combined_features"
    content: ["all_ts", "combined_features"]

# Visualization section - creates plots of selected signals
visualization:
  # Create a time series plot of heart rate signals from both devices
  - type: time_series
    signals: ["hr"]  # All heart rate signals
    layout: vertical
    title: "Heart Rate Comparison: All Devices"
    output: "results/visualizations/heart_rate_comparison.html"
    backend: plotly
    parameters:
      # width: 3000
      # height: 800
      x_label: "Time"
      y_label: "Heart Rate (bpm)"
      strict: false  # Skip missing signals with warning
      colorscale: "Plotly"  # Use Plotly's default qualitative colorscale

  # Plot accelerometer magnitude signals
  - type: time_series
    signals: ["accel_magnitude"]  # All accelerometer magnitude signals
    title: "Accelerometer Magnitude Signals"
    output: "results/visualizations/accel_magnitude.html"
    backend: bokeh
    parameters:
      # width: 1200
      # height: 800
      line_color: "blue"
      x_label: "Time"
      y_label: "Magnitude (mg)"
      strict: false
      downsample: '1S' # Resample to 1-second frequency for visualization

  # Create a grid layout with multiple signal types (including sleep stage)
  - type: time_series
    signals: ["hr", "accel_magnitude", "accel_angle", "sleep_stage_0"] # Added sleep_stage_0
    layout: grid
    title: "Multivariate Signal Dashboard"
    output: "results/visualizations/multivariate_dashboard.html"
    backend: plotly
    parameters:
      # width: 3000 
      # height: 600
      link_x_axes: true  # Synchronize x-axes for time alignment
      strict: false
      downsample: 20000 # Limit each subplot to max 20,000 points for performance
  # Create a comprehensive plot with all signals (including sleep stage) in separate subplots
  - type: time_series
    signals: ["hr", "accel_magnitude", "accel_angle", "sleep_stage_0"] # Added sleep_stage_0
    layout: vertical
    title: "All Signals Overview - Linked X-Axes"
    output: "results/visualizations/all_signals_overview-plotly.html"
    backend: plotly
    parameters:
      link_x_axes: true  # Ensure x-axes are linked across all subplots
      # downsample: 20000 # Limit each subplot to max 20,000 points for performance
      # width: 1200
      # height: 1800  # Taller to accommodate all subplots
      strict: false
  - type: time_series
    signals: ["hr", "accel_magnitude", "accel_angle"] # REMOVED sleep_stage_0
    layout: vertical
    title: "All Signals Overview - Linked X-Axes (with Sleep Stages)" # Updated title
    output: "results/visualizations/all_signals_overview-bokeh.html"
    backend: bokeh
    parameters:
      link_x_axes: true  # Ensure x-axes are linked across all subplots
      # downsample: 20000 # Limit each subplot to max 20,000 points for performance
      # width: 1800    # REMOVED: Let stretch_width manage width
      height: 600   # Keep fixed height for taller plots
      sizing_mode: stretch_width # Use stretch_width for consistent width
      overlay_sleep_stages: "sleep_stage_0" # Specify key for background stages
      strict: false
      # Optional: Customize background stage colors/alpha
      # stage_colors: { Awake: 'red', REM: 'purple', ... }
      # alpha: 0.15 # Make background even more subtle

  # Plotly version of the overview with sleep stage background
  - type: time_series
    signals: ["hr", "accel_magnitude", "accel_angle"] # Exclude sleep stage itself from main plot lines
    layout: vertical
    title: "All Signals Overview - Plotly (with Sleep Stages Background)"
    output: "results/visualizations/all_signals_overview_background-plotly.html"
    backend: plotly
    parameters:
      link_x_axes: true
      overlay_sleep_stages: "sleep_stage_0" # Specify key for background stages
      strict: false
      # Optional: Customize background stage colors/alpha for Plotly
      # stage_colors: { Awake: 'red', REM: 'purple', ... }
      # alpha: 0.15
      # Optional: Adjust legend position if needed
      # legend_x: 1.05
      # legend_y: 0.5
